{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from random import sample \n",
    "random.seed(1)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import networkx as nx\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from spektral.layers import GraphConv\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks=pd.read_csv('tracks.csv')\n",
    "tracks=tracks[['Unnamed: 0','track.7', 'track.8', 'track.9']].loc[2:]\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres=pd.read_csv('genres.csv')\n",
    "genres=genres.sort_values('parent')\n",
    "pd.set_option(\"max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_parent=dict()\n",
    "for i in genres.to_numpy():\n",
    "    genres_parent[i[0]]=i[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter=genres['parent']==0\n",
    "genres.where(filter, inplace=True)\n",
    "genres.dropna(subset = [\"parent\"], inplace=True)\n",
    "genres_id=dict()\n",
    "genres_list=list()\n",
    "for i in genres.to_numpy():\n",
    "    genres_list.append(i[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_id=dict()\n",
    "for i in genres.to_numpy():\n",
    "    genres_id[i[3]]=int(i[0])\n",
    "    genres_id[int(i[0])]=i[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_map_songs=dict()\n",
    "for i in genres_list:\n",
    "    genres_map_songs[i]=set()\n",
    "for i in tracks.to_numpy():\n",
    "    for j in i[-1].split('[')[1].split(']')[0].split(','):\n",
    "        try:genres_map_songs[genres_id[genres_parent[int(j.strip())]]].add(int(i[0])) \n",
    "        except: continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_songs=list()\n",
    "for i in genres_map_songs:\n",
    "    number_of_songs.append([len(list(genres_map_songs[i])), i]) \n",
    "number_of_songs.sort(reverse=True)\n",
    "number_of_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in genres_map_songs:\n",
    "    genres_map_songs[i]=list(genres_map_songs[i])\n",
    "number_of_songs=list()\n",
    "for i in genres_map_songs:\n",
    "    number_of_songs.append([len(genres_map_songs[i]), i]) \n",
    "number_of_songs.sort(reverse=True)\n",
    "genres_map_songs.pop('Easy Listening')\n",
    "genres_map_songs.pop('Old-Time / Historic')\n",
    "genres_map_songs.pop('Soul-RnB')\n",
    "genres_map_songs.pop('Blues')\n",
    "genres_map_songs.pop('Spoken')\n",
    "genres_map_songs.pop('Country')\n",
    "number_of_songs=list()\n",
    "for i in genres_map_songs:\n",
    "    number_of_songs.append([len(genres_map_songs[i]), i]) \n",
    "number_of_songs.sort(reverse=True)\n",
    "for i in genres_map_songs:\n",
    "    genres_map_songs[i]=sample(genres_map_songs[i], 1000)\n",
    "number_of_songs=list()\n",
    "for i in genres_map_songs:\n",
    "    number_of_songs.append([len(genres_map_songs[i]), i]) \n",
    "number_of_songs.sort(reverse=True)\n",
    "number_of_songs\n",
    "import json\n",
    "def set_default(obj):\n",
    "    if isinstance(obj, set):return list(obj)\n",
    "    raise TypeError\n",
    "file=json.dumps(genres_map_songs, sort_keys=True, indent=1, default=set_default)\n",
    "f = open('genres_vs_songs.json', 'w')\n",
    "f.write(file)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classical-- 1000\n",
      "Electronic-- 1000\n",
      "Experimental-- 1000\n",
      "Folk-- 1000\n",
      "Hip-Hop-- 1000\n",
      "Instrumental-- 1000\n",
      "International-- 1000\n",
      "Jazz-- 1000\n",
      "Pop-- 1000\n",
      "Rock-- 1000\n"
     ]
    }
   ],
   "source": [
    "genres_songs_map=open(\"genres_vs_songs.json\")\n",
    "genres_songs_map=json.load(genres_songs_map)\n",
    "for i in genres_songs_map:\n",
    "    print(i+\"-- %d\"%(len(genres_songs_map[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9425\n",
      "283\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "song_index_map=dict()\n",
    "song_genres_map=dict()\n",
    "index_song_map=dict()\n",
    "for i in genres_songs_map.values():\n",
    "    for j in i:\n",
    "        song_genres_map[j]=list()\n",
    "for i in genres_songs_map:\n",
    "    for j in genres_songs_map[i]:\n",
    "        song_genres_map[j].append(i)\n",
    "aux=0\n",
    "for i in song_genres_map:\n",
    "    song_index_map[i]=aux\n",
    "    aux=aux+1\n",
    "for i in song_index_map:\n",
    "    index_song_map[song_index_map[i]]=i\n",
    "\n",
    "one_gener_song=list()\n",
    "more_than_one_gener_song=list()\n",
    "count_one=0\n",
    "count_two=0\n",
    "count_more_than_two=0\n",
    "for i in song_genres_map.values():\n",
    "    if(len(i)==1):count_one=count_one+1\n",
    "    elif(len(i)==2): count_two=count_two+1\n",
    "    else: count_more_than_two=count_more_than_two+1\n",
    "for i in song_genres_map:\n",
    "    if(len(song_genres_map[i])==1):one_gener_song.append(i)\n",
    "    else: more_than_one_gener_song.append(i)\n",
    "print(count_one)\n",
    "print(count_two)\n",
    "print(count_more_than_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=dict()\n",
    "test=dict()\n",
    "validation=dict()\n",
    "train=dict()\n",
    "for i in genres_songs_map.keys():\n",
    "    temp[i]=list()\n",
    "    test[i]=list()\n",
    "    validation[i]=list()\n",
    "    train[i]=list()\n",
    "for i in one_gener_song:\n",
    "    temp[song_genres_map[i][0]].append(i)\n",
    "\n",
    "import random\n",
    "from random import sample \n",
    "\n",
    "random.seed(1)\n",
    "for i in temp:\n",
    "    aux=sample(temp[i],int(len(temp[i])*0.6))\n",
    "    test[i]=aux[0:int(len(aux)/2)]\n",
    "    validation[i]=aux[int(len(aux)/2):]\n",
    "    for j in temp[i]:\n",
    "        if(j not in aux): train[i].append(j)\n",
    "for i in more_than_one_gener_song:\n",
    "    for j in song_genres_map[i]:\n",
    "        train[j].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classical-- Train:  434, Validation:  283, Test:  283\n",
      "Electronic-- Train:  433, Validation:  284, Test:  283\n",
      "Experimental-- Train:  438, Validation:  281, Test:  281\n",
      "Folk-- Train:  442, Validation:  279, Test:  279\n",
      "Hip-Hop-- Train:  422, Validation:  289, Test:  289\n",
      "Instrumental-- Train:  435, Validation:  283, Test:  282\n",
      "International-- Train:  438, Validation:  281, Test:  281\n",
      "Jazz-- Train:  446, Validation:  277, Test:  277\n",
      "Pop-- Train:  436, Validation:  282, Test:  282\n",
      "Rock-- Train:  426, Validation:  287, Test:  287\n"
     ]
    }
   ],
   "source": [
    "# 0.3 from each genre\n",
    "for i in genres_songs_map.keys():\n",
    "    print(i+\"-- Train: % 2d, Validation: % 2d, Test: % 2d\"%(len(train[i]), len(validation[i]), len(test[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_song_id=list()\n",
    "for i in test.values():\n",
    "    for j in i:\n",
    "        test_song_id.append(j)\n",
    "train_song_id=list()\n",
    "for i in train.values():\n",
    "    for j in i:\n",
    "        train_song_id.append(j)\n",
    "validation_song_id=list()\n",
    "for i in validation.values():\n",
    "    for j in i:\n",
    "        validation_song_id.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=[None for _ in range(10)]\n",
    "temp_index=dict()\n",
    "count=0\n",
    "for i in genres_songs_map.keys():\n",
    "    temp_index[i]=count\n",
    "    count=count+1\n",
    "for i in temp_index: classes[temp_index[i]]=i\n",
    "    \n",
    "Y=np.zeros((max(index_song_map.keys())+1, 10))\n",
    "for i in index_song_map:\n",
    "    for j in song_genres_map[index_song_map[i]]:\n",
    "        Y[i][temp_index[j]]=1/len(song_genres_map[index_song_map[i]])\n",
    "\n",
    "train_bool=np.zeros((max(index_song_map.keys())+1,),dtype=bool)\n",
    "validation_bool=np.zeros((max(index_song_map.keys())+1,),dtype=bool)\n",
    "test_bool=np.zeros((max(index_song_map.keys())+1,),dtype=bool)\n",
    "\n",
    "for i in index_song_map:\n",
    "    if(index_song_map[i] in train_song_id):train_bool[i]=True\n",
    "    elif(index_song_map[i] in validation_song_id):validation_bool[i]=True\n",
    "    else: test_bool[i]=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "features=pd.read_csv('features.csv')\n",
    "features=features.loc[3:]\n",
    "temp=dict()\n",
    "for i in features.to_numpy():\n",
    "    if(int(i[0]) in song_genres_map.keys()):temp[int(i[0])]=[float(item) for item in i[1:].tolist()]\n",
    "\n",
    "X=list()\n",
    "for i in range(max(index_song_map.keys())+1):\n",
    "    X.append(temp[index_song_map[i]])\n",
    "X=np.asarray(X)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "X = StandardScaler().fit_transform(X)\n",
    "pca=PCA(n_components=187)\n",
    "X=pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from scipy.sparse import csr_matrix\n",
    "A=csr_matrix((max(song_index_map.values())+1, max(song_index_map.values())+1),dtype = np.int8).toarray() \n",
    "for i in train:\n",
    "    for j in train[i]:\n",
    "        for k in train[i]:\n",
    "            if(j!=k): \n",
    "                A[song_index_map[j]][song_index_map[k]]=1\n",
    "                A[song_index_map[k]][song_index_map[j]]=1\n",
    "\n",
    "from scipy import spatial\n",
    "\n",
    "for i in validation_song_id:\n",
    "    for j in train_song_id:\n",
    "        temp_val=1-spatial.distance.cosine(X[song_index_map[i]], X[song_index_map[j]])\n",
    "        if(temp_val>=0.5):\n",
    "            A[song_index_map[i]][song_index_map[j]]=1\n",
    "            A[song_index_map[j]][song_index_map[i]]=1\n",
    "#             print(str(song_genres_map[i])+\" \"+str(song_genres_map[j])+\" \"+str(temp_val))\n",
    "\n",
    "for i in test_song_id:\n",
    "    for j in train_song_id:\n",
    "        temp_val=1-spatial.distance.cosine(X[song_index_map[i]], X[song_index_map[j]])\n",
    "        if(temp_val>=0.5):\n",
    "            A[song_index_map[i]][song_index_map[j]]=1\n",
    "            A[song_index_map[j]][song_index_map[i]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph info:  Name: \n",
      "Type: Graph\n",
      "Number of nodes: 9711\n",
      "Number of edges: 1111260\n",
      "Average degree: 228.8662\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "A[A > 0] = 1\n",
    "G = nx.Graph(A)\n",
    "A = nx.adjacency_matrix(G)\n",
    "print('Graph info: ', nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 187)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 9711)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_4 (GraphConv)        (None, 10)           1870        input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 10)           0           graph_conv_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_5 (GraphConv)        (None, 10)           100         dropout_2[0][0]                  \n",
      "                                                                 input_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,970\n",
      "Trainable params: 1,970\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "channel_1 = 10\n",
    "channel_2 = 20# Number of channels in the first layer\n",
    "dropout = 0.5          # Dropout rate for the features\n",
    "l2_reg = 5e-4           # L2 regularization rate\n",
    "learning_rate = 1e-2    # Learning rate\n",
    "epochs = 2000           # Number of training epochs\n",
    "es_patience = 10        # Patience for early stopping\n",
    "\n",
    "# Preprocessing operations\n",
    "A = GraphConv.preprocess(A).astype('f4')\n",
    "\n",
    "# Model definition\n",
    "X_in = Input(shape=(X.shape[1], ))\n",
    "fltr_in = Input((X.shape[0], ), sparse=True)\n",
    "\n",
    "graph_conv_1 = GraphConv(channel_1,\n",
    "                         activation='relu',\n",
    "                         kernel_regularizer=l2(l2_reg),\n",
    "                         use_bias=False)([X_in,fltr_in])\n",
    "\n",
    "dropout_1 = Dropout(dropout)(graph_conv_1)\n",
    "\n",
    "# graph_conv_2 = GraphConv(channel_2,\n",
    "#                          activation='relu',\n",
    "#                          kernel_regularizer=l2(l2_reg),\n",
    "#                          use_bias=False)([dropout_1, fltr_in])\n",
    "# dropout_2 = Dropout(dropout)(graph_conv_2)\n",
    "\n",
    "\n",
    "graph_conv_3 = GraphConv(10,\n",
    "                         activation='softmax',\n",
    "                         use_bias=False)([dropout_1, fltr_in])\n",
    "\n",
    "# Build model\n",
    "model = Model(inputs=[X_in, fltr_in], outputs=graph_conv_3)\n",
    "optimizer = Adam(lr=learning_rate)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              weighted_metrics=['acc'])\n",
    "model.summary()\n",
    "\n",
    "tbCallBack_GCN = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir='./Tensorboard_GCN_FMA',\n",
    ")\n",
    "callback_GCN = [tbCallBack_GCN] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2020 - acc: 0.0946 - val_loss: 0.8220 - val_acc: 0.1026\n",
      "Epoch 2/2000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 1.1326 - acc: 0.0995 - val_loss: 0.7856 - val_acc: 0.1104\n",
      "Epoch 3/2000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 1.0920 - acc: 0.1019 - val_loss: 0.7553 - val_acc: 0.1210\n",
      "Epoch 4/2000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 1.0401 - acc: 0.1155 - val_loss: 0.7310 - val_acc: 0.1331\n",
      "Epoch 5/2000\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 1.0047 - acc: 0.1374 - val_loss: 0.7116 - val_acc: 0.1440\n",
      "Epoch 6/2000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9676 - acc: 0.1679 - val_loss: 0.6965 - val_acc: 0.1607\n",
      "Epoch 7/2000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.9509 - acc: 0.1773 - val_loss: 0.6849 - val_acc: 0.1713\n",
      "Epoch 8/2000\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.9290 - acc: 0.2064 - val_loss: 0.6758 - val_acc: 0.1805\n",
      "Epoch 9/2000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9146 - acc: 0.2283 - val_loss: 0.6685 - val_acc: 0.1897\n",
      "Epoch 10/2000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.8983 - acc: 0.2485 - val_loss: 0.6626 - val_acc: 0.1989\n",
      "Epoch 11/2000\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.8835 - acc: 0.2561 - val_loss: 0.6577 - val_acc: 0.2063\n",
      "Epoch 12/2000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8792 - acc: 0.2632 - val_loss: 0.6538 - val_acc: 0.2141\n",
      "Epoch 13/2000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8695 - acc: 0.2770 - val_loss: 0.6507 - val_acc: 0.2212\n",
      "Epoch 14/2000\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.8622 - acc: 0.2891 - val_loss: 0.6481 - val_acc: 0.2272\n",
      "Epoch 15/2000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8557 - acc: 0.3071 - val_loss: 0.6462 - val_acc: 0.2357\n",
      "Epoch 16/2000\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.8376 - acc: 0.3413 - val_loss: 0.6446 - val_acc: 0.2374\n",
      "Epoch 17/2000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.8418 - acc: 0.3423 - val_loss: 0.6432 - val_acc: 0.2420\n",
      "Epoch 18/2000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8292 - acc: 0.3583 - val_loss: 0.6421 - val_acc: 0.2502\n",
      "Epoch 19/2000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8177 - acc: 0.3809 - val_loss: 0.6412 - val_acc: 0.2573\n",
      "Epoch 20/2000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8162 - acc: 0.3802 - val_loss: 0.6404 - val_acc: 0.2640\n",
      "Epoch 21/2000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8162 - acc: 0.3861 - val_loss: 0.6397 - val_acc: 0.2707\n",
      "Epoch 22/2000\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.8016 - acc: 0.4038 - val_loss: 0.6392 - val_acc: 0.2757\n",
      "Epoch 23/2000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7866 - acc: 0.4110 - val_loss: 0.6388 - val_acc: 0.2817\n",
      "Epoch 24/2000\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7937 - acc: 0.4019 - val_loss: 0.6384 - val_acc: 0.2841\n",
      "Epoch 25/2000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7862 - acc: 0.4095 - val_loss: 0.6381 - val_acc: 0.2866\n",
      "Epoch 26/2000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7720 - acc: 0.4327 - val_loss: 0.6380 - val_acc: 0.2923\n",
      "Epoch 27/2000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7782 - acc: 0.4238 - val_loss: 0.6381 - val_acc: 0.2941\n",
      "Epoch 28/2000\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7665 - acc: 0.4258 - val_loss: 0.6382 - val_acc: 0.2976\n",
      "Epoch 29/2000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7534 - acc: 0.4363 - val_loss: 0.6384 - val_acc: 0.2983\n",
      "Epoch 30/2000\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7422 - acc: 0.4526 - val_loss: 0.6387 - val_acc: 0.3015\n",
      "Epoch 31/2000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7433 - acc: 0.4363 - val_loss: 0.6390 - val_acc: 0.3050\n",
      "Epoch 32/2000\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.7453 - acc: 0.4519 - val_loss: 0.6391 - val_acc: 0.3033\n",
      "Epoch 33/2000\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.7392 - acc: 0.4516 - val_loss: 0.6393 - val_acc: 0.3079\n",
      "Epoch 34/2000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7346 - acc: 0.4689 - val_loss: 0.6396 - val_acc: 0.3093\n",
      "Epoch 35/2000\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7342 - acc: 0.4556 - val_loss: 0.6397 - val_acc: 0.3093\n",
      "Epoch 36/2000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7250 - acc: 0.4575 - val_loss: 0.6400 - val_acc: 0.3125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20242b96e80>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data = ([X, A], Y, validation_bool)\n",
    "model.fit([X, A],\n",
    "          Y,\n",
    "          sample_weight=train_bool,\n",
    "          epochs=epochs,\n",
    "          batch_size=X.shape[0],\n",
    "          validation_data=validation_data,\n",
    "          shuffle=False,\n",
    "          callbacks=[\n",
    "              EarlyStopping(patience=es_patience,  restore_best_weights=True),\n",
    "              tbCallBack_GCN\n",
    "          ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN Classification Report: \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    Classical       0.45      0.61      0.52       283\n",
      "   Electronic       0.22      0.35      0.27       283\n",
      " Experimental       0.18      0.06      0.09       281\n",
      "         Folk       0.35      0.34      0.35       279\n",
      "      Hip-Hop       0.38      0.36      0.37       289\n",
      " Instrumental       0.14      0.08      0.10       282\n",
      "International       0.28      0.34      0.31       281\n",
      "         Jazz       0.31      0.32      0.32       277\n",
      "          Pop       0.21      0.09      0.12       282\n",
      "         Rock       0.27      0.44      0.34       287\n",
      "\n",
      "     accuracy                           0.30      2824\n",
      "    macro avg       0.28      0.30      0.28      2824\n",
      " weighted avg       0.28      0.30      0.28      2824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_te = X[test_bool]\n",
    "A_te = A[test_bool,:][:,test_bool]\n",
    "y_te = Y[test_bool]\n",
    "\n",
    "y_pred = model.predict([X_te, A_te], batch_size=X.shape[0])\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(np.argmax(y_te,axis=1), np.argmax(y_pred,axis=1), target_names=classes)\n",
    "print('GCN Classification Report: \\n {}'.format(report))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
